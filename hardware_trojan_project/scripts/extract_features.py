import torch
import torch.nn as nn
from torchvision import models, transforms, datasets
from torch.utils.data import DataLoader
import numpy as np
import os
import pickle
from tqdm import tqdm
import multiprocessing

# ==================== ØªÙ†Ø¸ÛŒÙ…Ø§Øª ====================
BATCH_SIZE = 16  # Ú©Ù…ØªØ± Ú©Ø±Ø¯Ù… ØªØ§ Ø±Ù… Ù¾Ø± Ù†Ø´ÙˆØ¯
IMG_SIZE = 224

def main():
    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ±Ù‡Ø§
    SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
    PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
    DATA_DIR = os.path.join(PROJECT_ROOT, 'dataset', 'images_heatmap')
    OUTPUT_FILE = os.path.join(PROJECT_ROOT, 'data', 'features.pkl')

    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)

    print("ğŸš€ Starting Feature Extraction (Safe Mode)...")
    print(f"ğŸ“‚ Reading images from: {DATA_DIR}")

    if not os.path.exists(DATA_DIR) or not os.listdir(DATA_DIR):
        print("âŒ Error: Image directory is empty or missing!")
        exit()

    # ØªÙ†Ø¸ÛŒÙ… Ø¯Ø³ØªÚ¯Ø§Ù‡ (GPU/CPU)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"âš™ï¸ Using device: {device}")

    # Ù„ÙˆØ¯ Ù…Ø¯Ù„ ResNet18
    base_model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
    feature_extractor = nn.Sequential(*list(base_model.children())[:-1])
    feature_extractor = feature_extractor.to(device)
    feature_extractor.eval()

    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯ÛŒØªØ§
    transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    try:
        dataset = datasets.ImageFolder(root=DATA_DIR, transform=transform)
        # Ù†Ú©ØªÙ‡ Ú©Ù„ÛŒØ¯ÛŒ: Ø¯Ø± ÙˆÛŒÙ†Ø¯ÙˆØ² Ø¨Ù‡ØªØ± Ø§Ø³Øª num_workers=0 Ø¨Ø§Ø´Ø¯ ØªØ§ Ú©Ø±Ø´ Ù†Ú©Ù†Ø¯
        # Ø§Ú¯Ø± Ø³ÛŒØ³ØªÙ… Ù‚ÙˆÛŒ Ø¯Ø§Ø±ÛŒØ¯ØŒ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ num_workers=2 Ø¨Ú¯Ø°Ø§Ø±ÛŒØ¯ ÙˆÙ„ÛŒ Ø­ØªÙ…Ø§ Ø¯Ø§Ø®Ù„ main
        dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)
        print(f"âœ… Found {len(dataset)} images in classes: {dataset.classes}")
    except Exception as e:
        print(f"âŒ Error loading images: {e}")
        exit()

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ
    all_features = []
    all_labels = []

    print("â³ Extracting features...")

    with torch.no_grad():
        for inputs, labels in tqdm(dataloader):
            inputs = inputs.to(device)
            features = feature_extractor(inputs)
            features = features.view(features.size(0), -1).cpu().numpy()
            all_features.append(features)
            all_labels.append(labels.numpy())

    # Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ
    X = np.vstack(all_features)
    y = np.concatenate(all_labels)

    print(f"ğŸ“Š Feature Matrix Shape: {X.shape}")
    
    data_to_save = {
        'features': X,
        'labels': y,
        'class_names': dataset.classes
    }

    with open(OUTPUT_FILE, 'wb') as f:
        pickle.dump(data_to_save, f)

    print(f"âœ… Success! Features saved to: {OUTPUT_FILE}")

# Ù…Ø­Ø§ÙØ¸Øª Ø¨Ø±Ø§ÛŒ ÙˆÛŒÙ†Ø¯ÙˆØ²
if __name__ == '__main__':
    multiprocessing.freeze_support() # Ø§Ø®ØªÛŒØ§Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ù…Ù†ÛŒØª Ø¨ÛŒØ´ØªØ±
    main()
