{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af794a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Stage 2.2: Train CNN Model for Vulnerability Classification\n",
    "Trains a Convolutional Neural Network on generated images\n",
    "to classify circuit vulnerability (Low/Medium/High)\n",
    "\n",
    "Model: Custom CNN or ResNet18\n",
    "Framework: PyTorch\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Project root\n",
    "PROJECT_ROOT = Path(__file__).resolve().parent.parent\n",
    "DATASET_DIR = PROJECT_ROOT / 'dataset'\n",
    "IMAGES_DIR = DATASET_DIR / 'images' / 'all'\n",
    "MODELS_DIR = PROJECT_ROOT / 'models'\n",
    "RESULTS_DIR = PROJECT_ROOT / 'results'\n",
    "\n",
    "# Create directories\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ================== CONFIGURATION ==================\n",
    "\n",
    "# Training hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Image parameters\n",
    "IMAGE_SIZE = 224\n",
    "NUM_CLASSES = 3\n",
    "\n",
    "# Class mapping\n",
    "CLASS_NAMES = ['Low', 'Medium', 'High']\n",
    "CLASS_TO_IDX = {'Low': 0, 'Medium': 1, 'High': 2}\n",
    "IDX_TO_CLASS = {0: 'Low', 1: 'Medium', 2: 'High'}\n",
    "\n",
    "# Device configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nðŸš€ Using device: {DEVICE}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "# ================== DATASET CLASS ==================\n",
    "\n",
    "class VulnerabilityDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for vulnerability images\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe: pd.DataFrame, images_dir: Path, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: DataFrame with columns ['filename', 'label', 'split']\n",
    "            images_dir: Directory containing images\n",
    "            transform: Optional transform to be applied on images\n",
    "        \"\"\"\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # Get image info\n",
    "        row = self.dataframe.iloc[idx]\n",
    "        circuit_name = row['circuit_name']\n",
    "        sample_id = row['sample_id']\n",
    "        label_str = row['vulnerability_label']\n",
    "        \n",
    "        # Construct filename\n",
    "        filename = f\"{circuit_name}_{sample_id:05d}_{label_str}.png\"\n",
    "        img_path = self.images_dir / filename\n",
    "        \n",
    "        # Load image\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {img_path}: {e}\")\n",
    "            # Return a blank image if error\n",
    "            image = Image.new('RGB', (IMAGE_SIZE, IMAGE_SIZE), color=(0, 0, 0))\n",
    "        \n",
    "        # Get label\n",
    "        label = CLASS_TO_IDX[label_str]\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# ================== DATA TRANSFORMS ==================\n",
    "\n",
    "def get_transforms(augment: bool = False):\n",
    "    \"\"\"\n",
    "    Get image transforms\n",
    "    \n",
    "    Args:\n",
    "        augment: Whether to apply data augmentation\n",
    "    \"\"\"\n",
    "    if augment:\n",
    "        # Training transforms with augmentation\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(IMAGE_SIZE, scale=(0.8, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    else:\n",
    "        # Validation/Test transforms (no augmentation)\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    return transform\n",
    "\n",
    "# ================== CNN MODEL ARCHITECTURES ==================\n",
    "\n",
    "class CustomCNN(nn.Module):\n",
    "    \"\"\"Custom CNN architecture for vulnerability classification\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=3):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # 224 -> 112\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # 112 -> 56\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)  # 56 -> 28\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)  # 28 -> 14\n",
    "        \n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.pool5 = nn.MaxPool2d(2, 2)  # 14 -> 7\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(512 * 7 * 7, 1024)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(1024, 256)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Conv block 1\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Conv block 2\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Conv block 3\n",
    "        x = self.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # Conv block 4\n",
    "        x = self.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        # Conv block 5\n",
    "        x = self.relu(self.bn5(self.conv5(x)))\n",
    "        x = self.pool5(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "def get_resnet18_model(num_classes=3, pretrained=True):\n",
    "    \"\"\"\n",
    "    Get ResNet18 model (transfer learning)\n",
    "    \n",
    "    Args:\n",
    "        num_classes: Number of output classes\n",
    "        pretrained: Whether to use pretrained weights\n",
    "    \"\"\"\n",
    "    model = models.resnet18(pretrained=pretrained)\n",
    "    \n",
    "    # Modify final layer\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, num_classes)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ================== TRAINING FUNCTIONS ==================\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Trainer class for CNN model\"\"\"\n",
    "    \n",
    "    def __init__(self, model, device, model_name='CustomCNN'):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            self.optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "        )\n",
    "        \n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accs = []\n",
    "        self.val_accs = []\n",
    "        \n",
    "        self.best_val_acc = 0.0\n",
    "        self.best_model_path = None\n",
    "    \n",
    "    def train_epoch(self, dataloader):\n",
    "        \"\"\"Train for one epoch\"\"\"\n",
    "        self.model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(dataloader, desc='Training')\n",
    "        for images, labels in pbar:\n",
    "            images = images.to(self.device)\n",
    "            labels = labels.to(self.device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = self.model(images)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def validate(self, dataloader):\n",
    "        \"\"\"Validate the model\"\"\"\n",
    "        self.model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pbar = tqdm(dataloader, desc='Validation')\n",
    "            for images, labels in pbar:\n",
    "                images = images.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = self.model(images)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                # Statistics\n",
    "                running_loss += loss.item() * images.size(0)\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                # Update progress bar\n",
    "                pbar.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'acc': f'{100.*correct/total:.2f}%'\n",
    "                })\n",
    "        \n",
    "        epoch_loss = running_loss / total\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        return epoch_loss, epoch_acc\n",
    "    \n",
    "    def train(self, train_loader, val_loader, num_epochs):\n",
    "        \"\"\"Train the model\"\"\"\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"TRAINING {self.model_name}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Device: {self.device}\")\n",
    "        print(f\"Epochs: {num_epochs}\")\n",
    "        print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "        print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "            print(\"-\" * 70)\n",
    "            \n",
    "            # Train\n",
    "            train_loss, train_acc = self.train_epoch(train_loader)\n",
    "            self.train_losses.append(train_loss)\n",
    "            self.train_accs.append(train_acc)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_acc = self.validate(val_loader)\n",
    "            self.val_losses.append(val_loss)\n",
    "            self.val_accs.append(val_acc)\n",
    "            \n",
    "            # Learning rate scheduling\n",
    "            self.scheduler.step(val_loss)\n",
    "            \n",
    "            # Print epoch results\n",
    "            print(f\"\\nEpoch {epoch+1} Results:\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "            print(f\"  Val Loss:   {val_loss:.4f}, Val Acc:   {val_acc:.2f}%\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                self.best_model_path = MODELS_DIR / f'{self.model_name}_best.pth'\n",
    "                torch.save({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                    'val_acc': val_acc,\n",
    "                    'val_loss': val_loss,\n",
    "                }, self.best_model_path)\n",
    "                print(f\"  âœ“ Saved best model (val_acc: {val_acc:.2f}%)\")\n",
    "        \n",
    "        training_time = time.time() - start_time\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"TRAINING COMPLETED\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Total Training Time: {training_time/60:.2f} minutes\")\n",
    "        print(f\"Best Validation Accuracy: {self.best_val_acc:.2f}%\")\n",
    "        print(f\"Best Model Saved: {self.best_model_path}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    def plot_training_history(self):\n",
    "        \"\"\"Plot training history\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Loss plot\n",
    "        ax1.plot(self.train_losses, label='Train Loss', marker='o')\n",
    "        ax1.plot(self.val_losses, label='Val Loss', marker='s')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_title(f'{self.model_name} - Training and Validation Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Accuracy plot\n",
    "        ax2.plot(self.train_accs, label='Train Accuracy', marker='o')\n",
    "        ax2.plot(self.val_accs, label='Val Accuracy', marker='s')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy (%)')\n",
    "        ax2.set_title(f'{self.model_name} - Training and Validation Accuracy')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plot_path = RESULTS_DIR / f'{self.model_name}_training_history.png'\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ“ Saved training history plot: {plot_path}\")\n",
    "        plt.close()\n",
    "\n",
    "def evaluate_model(model, dataloader, device, class_names, model_name='Model'):\n",
    "    \"\"\"Evaluate model on test set\"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"EVALUATING {model_name} ON TEST SET\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc='Testing'):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=class_names, digits=4))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{model_name} - Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    cm_path = RESULTS_DIR / f'{model_name}_confusion_matrix.png'\n",
    "    plt.savefig(cm_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"\\nâœ“ Saved confusion matrix: {cm_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = 100. * (all_preds == all_labels).sum() / len(all_labels)\n",
    "    print(f\"\\nTest Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return accuracy, cm\n",
    "\n",
    "# ================== MAIN EXECUTION ==================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function\"\"\"\n",
    "    print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                                                                          â•‘\n",
    "â•‘              STAGE 2.2: CNN MODEL TRAINING                               â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•‘    Hardware Trojan Vulnerability Assessment Project                      â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "    \"\"\")\n",
    "    \n",
    "    # Load dataset\n",
    "    print(\"\\nLoading dataset...\")\n",
    "    df = pd.read_csv(DATASET_DIR / 'dataset_with_splits.csv')\n",
    "    \n",
    "    # Split data\n",
    "    train_df = df[df['split'] == 'train']\n",
    "    val_df = df[df['split'] == 'val']\n",
    "    test_df = df[df['split'] == 'test']\n",
    "    \n",
    "    print(f\"Train samples: {len(train_df)}\")\n",
    "    print(f\"Val samples:   {len(val_df)}\")\n",
    "    print(f\"Test samples:  {len(test_df)}\")\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = VulnerabilityDataset(train_df, IMAGES_DIR, transform=get_transforms(augment=True))\n",
    "    val_dataset = VulnerabilityDataset(val_df, IMAGES_DIR, transform=get_transforms(augment=False))\n",
    "    test_dataset = VulnerabilityDataset(test_df, IMAGES_DIR, transform=get_transforms(augment=False))\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Option 1: Custom CNN\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"OPTION 1: TRAINING CUSTOM CNN\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    model_custom = CustomCNN(num_classes=NUM_CLASSES)\n",
    "    trainer_custom = Trainer(model_custom, DEVICE, model_name='CustomCNN')\n",
    "    trainer_custom.train(train_loader, val_loader, num_epochs=NUM_EPOCHS)\n",
    "    trainer_custom.plot_training_history()\n",
    "    \n",
    "    # Load best model and evaluate\n",
    "    checkpoint = torch.load(trainer_custom.best_model_path)\n",
    "    model_custom.load_state_dict(checkpoint['model_state_dict'])\n",
    "    acc_custom, cm_custom = evaluate_model(model_custom, test_loader, DEVICE, CLASS_NAMES, 'CustomCNN')\n",
    "    \n",
    "    # Option 2: ResNet18 (Transfer Learning)\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"OPTION 2: TRAINING RESNET18 (TRANSFER LEARNING)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    model_resnet = get_resnet18_model(num_classes=NUM_CLASSES, pretrained=True)\n",
    "    trainer_resnet = Trainer(model_resnet, DEVICE, model_name='ResNet18')\n",
    "    trainer_resnet.train(train_loader, val_loader, num_epochs=NUM_EPOCHS)\n",
    "    trainer_resnet.plot_training_history()\n",
    "    \n",
    "    # Load best model and evaluate\n",
    "    checkpoint = torch.load(trainer_resnet.best_model_path)\n",
    "    model_resnet.load_state_dict(checkpoint['model_state_dict'])\n",
    "    acc_resnet, cm_resnet = evaluate_model(model_resnet, test_loader, DEVICE, CLASS_NAMES, 'ResNet18')\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                                                                          â•‘\n",
    "â•‘            âœ“ STAGE 2.2 CNN TRAINING COMPLETED                            â•‘\n",
    "â•‘                                                                          â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "MODEL COMPARISON:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Custom CNN Test Accuracy:    {:.2f}%\n",
    "ResNet18 Test Accuracy:      {:.2f}%\n",
    "\n",
    "Best Model: {}\n",
    "\n",
    "FILES SAVED:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Models:\n",
    "  â”œâ”€ CustomCNN_best.pth\n",
    "  â””â”€ ResNet18_best.pth\n",
    "\n",
    "Results:\n",
    "  â”œâ”€ CustomCNN_training_history.png\n",
    "  â”œâ”€ CustomCNN_confusion_matrix.png\n",
    "  â”œâ”€ ResNet18_training_history.png\n",
    "  â””â”€ ResNet18_confusion_matrix.png\n",
    "\n",
    "Location: {}\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    \"\"\".format(\n",
    "        acc_custom, \n",
    "        acc_resnet,\n",
    "        \"ResNet18\" if acc_resnet > acc_custom else \"Custom CNN\",\n",
    "        RESULTS_DIR\n",
    "    ))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
