import torch
import torchvision.transforms as transforms
from torchvision import models
import torch.nn as nn  # Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ØªØºÛŒÛŒØ± Ù„Ø§ÛŒÙ‡ Ø¢Ø®Ø±
from PIL import Image
from pathlib import Path
import numpy as np

# ==================== ØªØ¹Ø±ÛŒÙ Ù…Ø³ÛŒØ±Ù‡Ø§ ====================
PROJECT_ROOT = Path(r"F:\Amin_Projects\University\VHDL\hardware_trojan_project")
MODELS_DIR = PROJECT_ROOT / "colab_outputs" / "models"
test_image_path = PROJECT_ROOT / "test_image_c17_trojan.png"
# =====================================================

print("="*80)
print("TEST 4: EXTRACT CNN FEATURES")
print("="*80 + "\n")

# 1. Ø³Ø§Ø®Øª Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…Ø¯Ù„ ResNet18
print("1ï¸âƒ£  Building ResNet-18 Architecture...")
try:
    # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù†Ø³Ø®Ù‡ Ø®Ø§Ù… ResNet18 (Ø¨Ø¯ÙˆÙ† ÙˆØ²Ù† Ø§ÙˆÙ„ÛŒÙ‡ØŒ Ú†ÙˆÙ† ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯Ù…Ø§Ù† Ø±Ø§ Ø¯Ø§Ø±ÛŒÙ…)
    cnn_model = models.resnet18(weights=None)
    
    # ØªØºÛŒÛŒØ± Ù„Ø§ÛŒÙ‡ Ø¢Ø®Ø± (fc) Ø¨Ø±Ø§ÛŒ ØªØ·Ø§Ø¨Ù‚ Ø¨Ø§ Ù…Ø¯Ù„ Ø¢Ù…ÙˆØ²Ø´â€ŒØ¯ÛŒØ¯Ù‡ (3 Ú©Ù„Ø§Ø³: Low, Medium, High)
    num_ftrs = cnn_model.fc.in_features
    cnn_model.fc = nn.Linear(num_ftrs, 3)
    
    print("   âœ… Architecture created!")
    
    # 2. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡
    print("2ï¸âƒ£  Loading Trained Weights...")
    weights_path = MODELS_DIR / "resnet18_best.pth"
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ ÙˆØ²Ù†â€ŒÙ‡Ø§
    state_dict = torch.load(weights_path, map_location='cpu', weights_only=False)
    
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ²Ù†â€ŒÙ‡Ø§ Ø±ÙˆÛŒ Ù…Ø¯Ù„
    cnn_model.load_state_dict(state_dict)
    print("   âœ… Weights loaded successfully!")

except Exception as e:
    print(f"   âŒ Error: {e}")
    exit()

# 3. ØªÙ†Ø¸ÛŒÙ… Ù…Ø¯Ù„ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§
device = torch.device('cpu')
cnn_model = cnn_model.to(device)
cnn_model.eval()

# 4. Ø­Ø°Ù Ù„Ø§ÛŒÙ‡ Ø¢Ø®Ø± Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ (Feature Extraction)
# Ù…Ø§ Ù„Ø§ÛŒÙ‡ fc (Ø¢Ø®Ø±ÛŒÙ† Ù„Ø§ÛŒÙ‡) Ø±Ø§ Ø­Ø°Ù Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ Ø¨Ø±Ø¯Ø§Ø± ÙˆÛŒÚ˜Ú¯ÛŒ 512 ØªØ§ÛŒÛŒ Ø¨Ú¯ÛŒØ±ÛŒÙ…
feature_extractor = torch.nn.Sequential(*list(cnn_model.children())[:-1])

# 5. Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ (Preprocessing)
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                        std=[0.229, 0.224, 0.225])
])

# 6. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªØµÙˆÛŒØ± ØªØ³Øª
if not test_image_path.exists():
    print(f"âŒ Error: Test image not found at {test_image_path}")
    exit()

test_image = Image.open(test_image_path).convert('RGB')
test_image_tensor = transform(test_image).unsqueeze(0).to(device)

print("\nðŸ”§ Extracting 512-D feature vector...")

# 7. Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆÛŒÚ˜Ú¯ÛŒ
with torch.no_grad():
    features = feature_extractor(test_image_tensor)
    features = features.view(features.size(0), -1) # Flatten (1, 512, 1, 1) -> (1, 512)
    features_np = features.cpu().numpy()

print(f"   âœ… Features extracted!")
print(f"   Shape: {features_np.shape}")
print(f"   First 10 features: {features_np[0, :10]}")
print(f"   Mean: {features_np.mean():.4f}")
print(f"   Std: {features_np.std():.4f}")

# 8. Ø°Ø®ÛŒØ±Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù…Ø±Ø­Ù„Ù‡ Ø¨Ø¹Ø¯
np.save(PROJECT_ROOT / "test_features.npy", features_np)
print(f"\nâœ… Features saved to: {PROJECT_ROOT / 'test_features.npy'}")
